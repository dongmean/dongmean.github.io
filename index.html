<!DOCTYPE html>
<!-- saved from url=(0034)https://songhwanjun.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Dongmin Park</title>
<meta content="Dongmin Park" name="Dongmin Park">
<link href="Dongmin_Park_files/style.css" rel="stylesheet" type="text/css">
<script src="Dongmin_Park_files/jquery-1.11.1.min.js" type="text/javascript"></script>
</head>


<body>
  <div class="menu"> <a href="https://dongmean.github.io/index.html">Home</a>  <a href="https://dongmean.github.io/index.html#publications">Publications</a> <a href="https://dongmean.github.io/index.html#talks">Invited Talks</a> <a href="https://dongmean.github.io/index.html#service">Services and Awards</a>
  </div>
  <div class="container">
    <table border="0">
      <tbody><tr>
        <td><img src="Dongmin_Park_files/dongmin_profile.jpg" width="130"></td>
        <td style="width: 10px">&nbsp;</td>
        <td valign="top" width="500">
          <span class="name">Dongmin Park</span>
          <p class="information"><br>
           <strong>Applied Research Team Lead</strong> at <a href="https://www.krafton.ai/ko/research/publications/">KRAFTON AI</a></p>
           <strong>Ph.D.</strong> at KAIST, advised by Professor <a href="https://www.kaistdmlab.org/jaegil">Jae-Gil Lee</a></p>
          <p class="information"><strong>Email</strong>: <span class="unselectable">dongmin.park</span><span class="hide">xkxkxk</span>@krafton.com</span> <span class="unselectable"></span> </p>
          <p class="information"><a href="https://scholar.google.com/citations?user=4xXYQl0AAAAJ&hl=en">Google Scholar</a> / <a href="https://www.linkedin.com/in/dongmin-park-82995613a/">Linked in</a> / <a href="https://www.overleaf.com/read/ccsdggkbwtnb">CV</a> / <a href="https://x.com/dongmin_park11">Twitter</a></p>
        </td>
      </tr>
    </tbody></table>
   I am an <strong>Applied Research Team Lead</strong> at KRAFTON AI, focusing on opening new frontiers for <strong>virtual/game agents</strong> by advancing state-of-the-art generative models like diffusion and LLMs. 
   Before joining KRAFTON, I completed my Ph.D. in 2024 at KAIST fortunately advised by Prof. Jae-Gil Lee. 
   During my Ph.D., I interned as a research scientist at industry labs including <u>Meta AI</u>, <u>Naver AI</u>, and <u>Krafton AI</u>, working with wonderful mentors.
   
    <a id="news" class="news"></a><span class="section">News</span>
    <p class="news">
      <strong>July 2025:</strong> Promoted to <u>Lead of the Applied Research Team</u> at KRAFTON.
    </p> 
    <p class="news">
      <strong>June 2025:</strong> One paper on 'LLM benchmark using Games' working with <u>NVIDIA AI</u> released at ArXiv.
    </p> 
    <p class="news">
      <strong>May 2025:</strong> Invited to serve as <u>Area Chair</u> at NeurIPS 2025.
    </p> 
    <p class="news">
      <strong>Mar 2025:</strong> Two papers on 'Test-time Alignment for Diffusion' and 'Diffusion with LLM Guidance' got <u>spotlight</u> from ICLR 2025.
    <p class="news">
      <strong>Jan 2025:</strong> Three papers on 'Diffusion, LLM, and Data-centric AI' accepted at ICLR 2025.
	</br>

    <a id="work_experience" class="work_experience"></a><span class="section">Work Experience</span>
    I've been fortunate to collaborate with amazing AI researchers throughout my research journey. If you're interested in collaborating, feel free to reach out!
    <ul>
    <li> <u>NVIDIA AI</u>, Research Collaboration (Co-workers: <a href="https://yoshi-suhara.com/">Yoshi Suhara</font></a>'s team) / Remote / March 2025-May 2025 </li>
    <li> <u>Meta AI</u>, Research Scientist Intern (Mentors: <a href="https://scholar.google.com/citations?user=FWpOydIAAAAJ&hl=en">Rui Wang</font></a>, <a href="https://www.weizmann.ac.il/math/ronen/home">Ronen Basri</font></a>, <a href="https://sites.google.com/site/sernam">Ser-Nam Lim</font></a>) / NYC, United States / Jun 2023-Aug 2023 </li>
    <li> <u>Krafton AI</u>, Research Scientist Intern (Mentor: <a href="https://scholar.google.com/citations?user=sCEl8r-n5VEC&hl=en">Kangwook Lee</font></a>, <a href="https://scholar.google.com/citations?user=hYi6i9sAAAAJ&hl=en">Dimitris Papailiopoulos</font></a> / Seoul, South Korea / Jul 2022-Sep 2022 </li>
    <li> <u>Naver AI</u>, Research Scientist Intern (Mentor: <a href="https://songhwanjun.github.io/">Hwanjun Song</font></a> / Seongnam, South Korea / Jun 2021-Dec 2021 </li>
    </ul>

    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications <a href="https://scholar.google.com/citations?user=4xXYQl0AAAAJ&hl=en"> (Google scholar profile) </a> </span>
    <table border="0" width="90%" class="paper">
    
    
    </tbody></table></br>
    <font size="4.5px"><strong>2025</strong></font>
    <table border="0" width="90%" class="paper"><tbody>
      
      <tr>
        <td>
          <img src="./images/pubpic/ArXiv25_Chess_LLM.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          D. Hwang, H. Lee, J. Choo, <strong>D. Park<sup>†</sup></strong>, J. Park<sup>†</sup>. <strong>Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess </strong>. <em>ArXiv 2025</em>.
          [<a href="https://arxiv.org/pdf/2507.00726"><font color="#000080">pdf</font></a>]
    </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/ArXiv25_Orak.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>D. Park</strong> et al. <strong>Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games</strong>. <em>ArXiv 2025</em>. <span class="oral">joint work with NVIDIA AI</span>.
          [<a href="https://arxiv.org/pdf/2506.03610"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/krafton-ai/Orak"><font color="#000080">code</font></a>]
    </td>
      </tr>
      
        <tr>
          <td>
            <img src="./images/pubpic/ICLR25_R2F.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <strong>D. Park</strong>, S. Kim, T. Moon, M. Kim, K. Lee, J. Cho. <strong>Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance</strong>. <em>ICLR 2025</em>. <span class="oral">spotlight</span>
            [<a href="https://arxiv.org/pdf/2410.22376"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/krafton-ai/Rare-to-Frequent"><font color="#000080">code</font></a>]
      </td>
        </tr>

      <tr>
        <td>
          <img src="./images/pubpic/ICLR25_DAS.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          S. Kim, M. Kim, <strong>D. Park<sup>†</sup></strong>. <strong>Test-time Alignment of Diffusion Models without Reward Over-optimization</strong>. <em>ICLR 2025</em>. <span class="oral">spotlight</span>
          [<a href="https://openreview.net/pdf?id=vi3DjUhFVm"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/krafton-ai/DAS"><font color="#000080">code</font></a>]
    </td>
      </tr>
      
        <tr>
          <td>
            <img src="./images/pubpic/ICLR25_AccuACL.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            J. Park, <strong>D. Park</strong>, JG. Lee. <strong>Active Learning for Continual Learning: Keeping the Past Alive in the Present</strong>. <em>ICLR 2025</em>.
            [<a href="https://arxiv.org/pdf/2501.14278"><font color="#000080">pdf</font></a>]
      </td>
        </tr>

    </tbody></table></br>
    <font size="4.5px"><strong>2024</strong></font>
    <table border="0" width="90%" class="paper"><tbody>
      
      <tr>
        <td>
          <img src="./images/pubpic/ArXiv24_Dialogue_Hallucination.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>D. Park</strong>, Z. Qian, G. Han, S. Lim. <strong>Mitigating Dialogue Hallucination for Large Vision Language Models via Adversarial Instruction Tuning</strong>. <em>ArXiv 2024</em>.
          [<a href="https://arxiv.org/pdf/2403.10492"><font color="#000080">pdf</font></a>]
    </td>
      </tr>
      
        <tr>
          <td>
            <img src="./images/pubpic/ICML24_AdaPromptCL.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            D. Kim, S. Yoon, <strong>D. Park</strong>, Y. Lee, J. Bang, H. Song, JG. Lee. <strong>One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning</strong>. <em>ICML 2024</em>.
            [<a href="https://arxiv.org/pdf/2311.12048"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaist-dmlab/AdaPromptCL"><font color="#000080">code</font></a>]
      </td>
        </tr>

    </tbody></table></br>
    <font size="4.5px"><strong>2023</strong></font>
    <table border="0" width="90%" class="paper"><tbody>

        <tr>
          <td>
            <img src="./images/pubpic/AAAI24_DropTop.PNG" class="PaperThumbnail" width="120">
          </td>
          <td>
            D. Kim, <strong>D. Park</strong>, Y. Shin, J. Bang, H. Song, JG. Lee. <strong>Adaptive Shorcut Debiasing for Online Continual Learning</strong>. <em>AAAI 2024</em>.
      </td>
        </tr>

        <tr>
          <td>
            <img src="./images/pubpic/NeurIPS23_PruneReL.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <strong>D. Park</strong>, S. Choi, D. Kim, H. Song, JG. Lee. <strong>Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy</strong>. <em>NeurIPS 2023</em>.
        [<a href="https://arxiv.org/pdf/2311.01002.pdf"><font color="#000080">pdf</font></a>]
        [<a href="https://github.com/kaist-dmlab/Prune4Rel"><font color="#000080">code</font></a>]
      </td>
        </tr>

        <tr>
          <td>
            <img src="./images/pubpic/ICML23_ContextAttached.PNG" class="PaperThumbnail" width="120">
          </td>
          <td>
            Y. Shin, S. Yoon, H. Song, <strong>D. Park</strong>, B. Kim, JG. Lee, BS. Lee. <strong>Context Consistency Regularization for Label Sparsity in Time Series</strong>. <em>ICML 2023</em>.
        [<a href="https://openreview.net/pdf?id=EvGOdASdHi"><font color="#000080">pdf</font></a>]
      </td>
        </tr>

    </tbody></table></br>
    <font size="4.5px"><strong>2022</strong></font>
    <table border="0" width="90%" class="paper"><tbody>

        <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/NIPS22_MQNet.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <strong>D. Park</strong>, Y. Shin, J. Bang, Y. Lee, H. Song, JG. Lee. <strong>Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set Active Learning</strong>. <em>NeurIPS 2022</em>.
        [<a href="https://arxiv.org/abs/2210.07805"><font color="#000080">pdf</font></a>]
        [<a href="https://github.com/kaist-dmlab/MQNet"><font color="#000080">code</font></a>]
      </td>
        </tr>

        <tr>
          <td>
            <img src="./images/pubpic/NIPS22W_AL_is_strong.png" class="PaperThumbnail" width="120">
          </td>
          <td>
            <strong>D. Park</strong>, D. Papailiopoulos, K. Lee. <strong>Active Learning is a Strong Baseline for Data Subset Selection</strong>. <em>NeurIPS Workshop 2022</em>.
        [<a href="https://openreview.net/pdf?id=PAgpyQ5rGS"><font color="#000080">pdf</font></a>]
        [<a href="https://github.com/dongmean/AL_vs_SubsetSelection"><font color="#000080">code</font></a>]
      </td>
        </tr>
      
        <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/ICDM22_PINCETTE.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <strong>D. Park</strong>, J. Kang, H. Song, S. Yoon, JG Lee. <strong>Multi-view POI-level Cellular Trajectory Reconstruction for Digital Contact Tracing of Infectious Diseases</strong>. <em> ICDM 2022 </em>.
            [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10027641"><font color="#000080">pdf</font></a>]
      </td>
        </tr>

        <tr>
          <td >
            <img src="./images/pubpic/TNNLS22_Survey.jpg" class="PaperThumbnail" width="120">
          </td>
          <td>
            H. Song, M. Kim, <strong>D. Park</strong>, Y. Shin, JG. Lee.  <strong>Learning from Noisy Labels with Deep Neural Networks: A Survey</strong>. <em>TNNLS 2022</em>. <span class="oral">The most cited survey paper on handling noisy labels with DNNs.</span>
            [<a href="https://arxiv.org/abs/2007.08199"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/songhwanjun/Awesome-Noisy-Labels"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/AAAI22_MELON.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            M. Kim, H. Song, Y. Shin, <strong>D. Park</strong>, K. Shin, JG. Lee.  <strong>Meta-Learning for Online Update of Recommender Systems</strong>. <em>AAAI 2022</em>.
            [<a href="https://www.aaai.org/AAAI22Papers/AAAI-2570.KimM.pdf"><font color="#000080">pdf</font></a>]
          </td>
        </tr>

    </tbody></table></br>
    <font size="4.5px"><strong>2021</strong></font>
    <table border="0" width="90%" class="paper"><tbody>

        <tr>
          <td>
            <img src="./images/pubpic/NeurIPS21_TAUFE.png" class="PaperThumbnail" width="120">
          </td>
          <td>
            <strong>D. Park</strong>, H. Song, M. Kim, JG. Lee.  <strong>Task-Agnostic Undesirable Feature Deactivation Using Out-of-Distribution Data</strong>. <em>NeurIPS 2021</em>.
            [<a href="https://openreview.net/pdf?id=4orlVaC95Bo"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaist-dmlab/TAUFE"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/KDD21_MORPH.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            H. Song, M. Kim, <strong>D. Park</strong>, Y. Shin, JG. Lee.  <strong>Robust Learning by Self-Transition for Handling Noisy Labels</strong>. <em>KDD 2021</em>. <span class="oral">Oral Presentation.</span>
            [<a href="https://arxiv.org/pdf/2012.04337.pdf"><font color="#000080">pdf</font></a>]
          </td>
        </tr>

    </tbody></table></br>
    <font size="4.5px"><strong>2020</strong></font>
    <table border="0" width="90%" class="paper"><tbody>
    
        <tr>
          <td>
            <img src="./images/pubpic/KDD20_HiCOVID.png" class="PaperThumbnail" width="120">
          </td>
          <td>
            M. Kim, J. Kang, Dim, H. Song, H. Min, Y. Nam, <strong>D. Park</strong>, JG. Lee.  <strong>Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea </strong>. <em>KDD 2020</em>. <span class="oral">Oral Presentation.</span>
            [<a href="https://dl.acm.org/doi/10.1145/3394486.3412864"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaist-dmlab/Hi-COVIDNet"><font color="#000080">code</font></a>]
          </td>
        </tr>   

          <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/ICMLW20_Early.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            H. Song, M. Kim, <strong>D. Park</strong>, JG. Lee.  <strong>How Does Early Stopping Help Generalization against Label Noise? </strong>. <em>ICML Workshop 2020</em>.
            [<a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-020.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://bit.ly/2l3g9Jx"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/pubpic/WWW20_Embed.png" class="PaperThumbnail" width="120">
          </td>
          <td>
            <strong>D. Park</strong>, H. Song, M. Kim, JG. Lee.  <strong>TRAP: Two-level Regularized Autoencoder-based Embedding for Power-law Distributed Data</strong>. <em>TheWebConf (WWW) 2020</em>. <span class="oral">Oral Presentation.</span>
            [<a href="http://dm.kaist.ac.kr/lab/papers/webconf20.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaist-dmlab/TRAP"><font color="#000080">code</font></a>]
          </td>
        </tr>   

    </tbody></table></br>
    <font size="4.5px"><strong>2019</strong></font>
    <table border="0" width="90%" class="paper"><tbody>

        <tr>
          <td bgcolor="#e9eaed">
            <img src="./images/pubpic/KDDW20_MLAT.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <strong>D. Park</strong>, S. Yoon, H. Song, JG. Lee.  <strong>MLAT: Metric Learning for kNN in Streaming Time Series</strong>. <em>KDD Workshop 2019</em>.
            [<a href="https://arxiv.org/pdf/1910.10368.pdf"><font color="#000080">pdf</font></a>]
          </td>
        </tr>   
    
    </tbody></table>

    <p>&nbsp;</p>

    <!-- Invited Talks -->
    <a id="talks" class="anchor"></a><span class="section">Invited Talks</span>
    <em>*** I am open to giving seminars in both academia and industry. Feel free to reach out! ***</em>
    <p class="service">July 2025: A Review on Post-training and Evaluating LLM Agents on Games, DISLab Seminar, KAIST </p>
    <p class="service">June 2024: Frontiers of Data-centric AI with Foundation Models in Game Industry, DS801 Seminar, KAIST</p>
    <p class="service">Nov 2023: Prioritizing Informative Features and Examples for Deep Learning from Noisy Data, DSLab Seminar, GIST</p> 

      <!-- Service & Awards -->
    <a id="service" class="anchor"></a><span class="section">Services</span>
    <p class="service">Area Chair: NeurIPS 2025</p>
    <p class="service">Conference Reviewer: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, KDD, AAAI, AISTATS, and TNNLS since 2021</p>
    <p class="service">Journal Reviewer: TNNLS, TMLR, TPAMI, and SIGRAPH Asia</p>  
    
    <a id="awards" class="anchor"></a><span class="section">Awards</span>
    <ul>
      <li> PhD Dissertation Award, KAIST Graduate School of Data Science, 2024 </li>
      <li> Best Annual PhD student, KAIST Graduate School of Data Science, 2021-2023 </li>
      <li> Outstanding Reviewer Award, International Conference on Machine Learning (ICML), 2022 </li>
      <li> Nuri Ph.D. Scholarship, The Korea Scholarship Foundation of Future Leaders ($18,000 + 2-year full scholarship) </li>
      <li> Best Poster Awards, KAIST AI Workshop (Sponsors: NAVER, LG AI, SKT), 2021 </li>
      <li> Qualcomm Innovation Awards, 2019 ($5,000) </li>
    </ul>

  <p><font color="#444444" face="Arial" size="2">&copy 2022 Dongmin Park. Thanks <a href="https://songhwanjun.github.io/"><font color="#000080">Dr. Hwanjun Song</font></a> and <a href="https://deqings.github.io/"><font color="#000080">Dr. Deqing Sun</font></a> for the template. </font></p>

  </div>
  <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "120"
    }
  </script>

</body></html>